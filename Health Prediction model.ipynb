{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfa525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee7000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading Data\n",
    "data = pd.read_csv('uncleaned_heart_data.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ab7715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values (NaN or null values) \n",
    "data.dropna(inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda81040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#      Normalization of  Unique Vales(2) to 1s & 0\n",
    "\n",
    "\n",
    "data['Sex'] = data['Sex'].apply(lambda x: 1 if x == 'Male' else 0)\n",
    "print(data[['Sex']])\n",
    "\n",
    "data['PhysicalActivities'] = data['PhysicalActivities'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['PhysicalActivities']])\n",
    "\n",
    "data['HadHeartAttack'] = data['HadHeartAttack'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['HadHeartAttack']])\n",
    "\n",
    "data['HadAngina'] = data['HadAngina'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['HadAngina']])\n",
    "\n",
    "data['HadStroke'] = data['HadStroke'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['HadStroke']])\n",
    "\n",
    "data['HadAsthma'] = data['HadAsthma'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['HadAsthma']])\n",
    "\n",
    "data['HadSkinCancer'] = data['HadSkinCancer'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['HadSkinCancer']])\n",
    "\n",
    "data['HadCOPD'] = data['HadCOPD'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['HadCOPD']])\n",
    "\n",
    "data['HadDepressiveDisorder'] = data['HadDepressiveDisorder'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['HadDepressiveDisorder']])\n",
    "\n",
    "data['HadKidneyDisease'] = data['HadKidneyDisease'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['HadKidneyDisease']])\n",
    "\n",
    "data['HadArthritis'] = data['HadArthritis'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['HadArthritis']])\n",
    "\n",
    "data['PhysicalActivities'] = data['PhysicalActivities'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['PhysicalActivities']])\n",
    "\n",
    "\n",
    "data['DeafOrHardOfHearing'] = data['DeafOrHardOfHearing'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['DeafOrHardOfHearing']])\n",
    "\n",
    "data['BlindOrVisionDifficulty'] = data['BlindOrVisionDifficulty'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['BlindOrVisionDifficulty']])\n",
    "\n",
    "data['DifficultyConcentrating'] = data['DifficultyConcentrating'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['DifficultyConcentrating']])\n",
    "\n",
    "\n",
    "data['DifficultyWalking'] = data['DifficultyWalking'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['DifficultyWalking']])\n",
    "\n",
    "\n",
    "data['DifficultyDressingBathing'] = data['DifficultyDressingBathing'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['DifficultyDressingBathing']])\n",
    "\n",
    "data['DifficultyErrands'] = data['DifficultyErrands'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['DifficultyErrands']])\n",
    "\n",
    "data['ChestScan'] = data['ChestScan'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['ChestScan']])\n",
    "\n",
    "data['AlcoholDrinkers'] = data['AlcoholDrinkers'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['AlcoholDrinkers']])\n",
    "\n",
    "data['ChestScan'] = data['ChestScan'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['ChestScan']])\n",
    "\n",
    "\n",
    "data['HIVTesting'] = data['HIVTesting'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['HIVTesting']])\n",
    "\n",
    "\n",
    "data['FluVaxLast12'] = data['FluVaxLast12'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['FluVaxLast12']])\n",
    "\n",
    "data['PneumoVaxEver'] = data['PneumoVaxEver'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['PneumoVaxEver']])\n",
    "\n",
    "data['HighRiskLastYear'] = data['HighRiskLastYear'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "print(data[['HighRiskLastYear']])\n",
    "\n",
    "data['CovidPos'] = data['CovidPos'].apply(lambda x: 1 if x == 'No' else 1)\n",
    "print(data['CovidPos'])\n",
    "\n",
    "data.to_csv('G_data.csv', index=False) #save all cleand data to this csv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeeae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#State Section  Cleaning abbrevations \n",
    "\n",
    "\n",
    "state_names = ['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California',\n",
    "               'Colorado', 'Connecticut', 'Delaware', 'District of Columbia',\n",
    "               'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana',\n",
    "               'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland',\n",
    "               'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi',\n",
    "               'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire',\n",
    "               'New Jersey', 'New Mexico', 'New York', 'North Carolina',\n",
    "               'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania',\n",
    "               'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee',\n",
    "               'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington',\n",
    "               'West Virginia', 'Wisconsin', 'Wyoming', 'Guam', 'Puerto Rico',\n",
    "               'Virgin Islands']\n",
    "\n",
    "#   state names to abbreviations\n",
    "state_abbreviations = {\n",
    "    'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR',\n",
    "    'California': 'CA', 'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC', 'Florida': 'FL', 'Georgia': 'GA', 'Hawaii': 'HI',\n",
    "    'Idaho': 'ID', 'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA', 'Kansas': 'KS',\n",
    "    'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS',\n",
    "    'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH', 'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY',\n",
    "    'North Carolina': 'NC', 'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI', 'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD', 'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT',\n",
    "    'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA', 'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI', 'Wyoming': 'WY', 'Guam': 'GU', 'Puerto Rico': 'PR',\n",
    "    'Virgin Islands': 'VI'\n",
    "}\n",
    "\n",
    "#  normalizing the columns\n",
    "data['State'] = data['State'].map(state_abbreviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42646c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf03650",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization using Mapping \n",
    "\n",
    "#GeneralHealth\n",
    "health_mapping = {'Poor': 0, 'Fair': 1, 'Good':2, 'Very good': 3, 'Excellent': 4}\n",
    "data['GeneralHealth'] = data['GeneralHealth'].map(health_mapping)\n",
    "\n",
    "\n",
    "\n",
    "#LastCheckupTime\n",
    "LastCheckupTime_mapping = {\"5 or more years ago\": 0, \"Within past 5 years (2 years but less than 5 years ago)]\": 1, \"Within past 2 years (1 year but less than 2 years ago)\": 2, \"Within past year (anytime less than 12 months ago)\":3 }\n",
    "data['LastCheckupTime'] = data['LastCheckupTime'].map(LastCheckupTime_mapping)\n",
    "\n",
    "\n",
    "#RemovedTeeth\n",
    "RemovedTeeth_mapping = {'All': 0, '6 or more, but not all':1, '1 to 5': 2, 'None of them':3}\n",
    "data['RemovedTeeth'] = data['RemovedTeet'].map(RemovedTeeth_mapping)\n",
    "\n",
    "\n",
    "\n",
    "#HadDiabetes                     \n",
    "HadDiabetes_mapping = {'Poor': 0, 'Fair': 1, 'Good': 2, 'Very good': 3}\n",
    "data['HadDiabetes'] = data['HadDiabetes'].map(HadDiabetes_mapping)\n",
    "\n",
    "\n",
    "\n",
    "#SmokerStatus\n",
    "SmokerStatus_mapping = {'Current smoker - now smokes every day': 0, 'Current smoker - now smokes some days':1, 'Former smoker': 2, 'Never smoked': 3}\n",
    "data['SmokerStatus'] = data['SmokerStatus'].map(SmokerStatus_mapping)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#ECigaretteUsage\n",
    "ECigaretteUsage_mapping = {'Use them every day':0, 'Use them some days': 1, 'Use them some days': 2, 'Never used e-cigarettes in my entire life': 3}\n",
    "data['ECigaretteUsage'] = data['ECigaretteUsage'].map(ECigaretteUsage_mapping)\n",
    "\n",
    "\n",
    "\n",
    "#TetanusLast10Tdap\n",
    "TetanusLast10Tdap_mapping = {'No, did not receive any tetanus shot in the past 10 years': 0, 'Yes, received tetanus shot, but not Tdap': 1, 'Yes, received tetanus shot but not sure what type': 2, 'Yes, received Tdap': 3}\n",
    "data['TetanusLast10Tdap'] = data['TetanusLast10Tdap'].map(TetanusLast10Tdap_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290fd3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Co-orealtion & Pair plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "correlation = data.corr()\n",
    "\n",
    "# plot size\n",
    "plt.figure(figsize=(30, 40))\n",
    "\n",
    "# Creating  heatmap \n",
    "sns.heatmap(correlation, xticklabels=correlation.columns, yticklabels=correlation.columns, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=.5)\n",
    "\n",
    "# Rotate the x-axis \n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e895c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed20f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################    EDA   ######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e66af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828d77ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Load your data\n",
    "# Replace 'your_data.csv' with the actual file name or use your own method to load the data\n",
    "data = pd.read_csv('G_data.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d303d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bivariate Analysis - Pair Plot\n",
    "sns.pairplot(data, hue='HadHeartAttack', diag_kind='kde')\n",
    "plt.suptitle('Pair Plot for HadHeartAttack')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Count plot for HadHeartAttack\n",
    "sns.countplot(x='HadHeartAttack', data=data)\n",
    "plt.title('Distribution of HadHeartAttack')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#  Feature Engineering\n",
    "data['AgeCategory'] = pd.cut(data['AgeCategory'], bins=[18, 35, 50, 65, 100], labels=['18-35', '36-50', '51-65', '66+'])\n",
    "\n",
    "\n",
    "# Count plot for the new 'AgeGroup' feature\n",
    "sns.countplot(x='AgeGroup', hue='HadHeartAttack', data=data)\n",
    "plt.title('Distribution of AgeGroup based on HadHeartAttack')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Feature: BMI Category\n",
    "data['BMICategory'] = pd.cut(data['BMI'], bins=[0, 18.5, 25, 30, 35, 40, 100], labels=['Underweight', 'Normal', 'Overweight', 'Obese I', 'Obese II', 'Obese III'])\n",
    "\n",
    "# Count plot for BMICategory' feature\n",
    "sns.countplot(x='BMICategory', hue='HadHeartAttack', data=data)\n",
    "plt.title('Distribution of BMICategory based on HadHeartAttack')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Feature: Physical and Mental Health Index\n",
    "data['HealthIndex'] = data['PhysicalHealthDays'] + data['MentalHealthDays']\n",
    "\n",
    "# Pair plot for the new 'HealthIndex' feature\n",
    "sns.pairplot(data, vars=['PhysicalHealthDays', 'MentalHealthDays', 'HealthIndex'], hue='HadHeartAttack', diag_kind='kde')\n",
    "plt.suptitle('Pair Plot for HealthIndex based on HadHeartAttack')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'data' is your DataFrame and 'HadHeartAttack' is a categorical variable\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a count plot\n",
    "sns.countplot(x='HadHeartAttack', data=data)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Had Heart Attack')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count Plot for Had Heart Attack')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74989059",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################# MODEL #######################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b90a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below code for ,LogisticRegression ,Decision Tree, RandomForest , Support Vector Machine,Gradient Boosting, Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e83246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "# Read data from CSV file\n",
    "data = pd.read_csv(\"Encoded1.csv\")\n",
    "\n",
    "\n",
    "# Function to train and evaluate various machine learning models\n",
    "def train_and_evaluate_models(X_train, X_test, y_train, y_test):\n",
    "    # Define a dictionary of machine learning models\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(),\n",
    "        'Decision Tree': DecisionTreeClassifier(),\n",
    "        'Random Forest': RandomForestClassifier(),\n",
    "        'Support Vector Machine': SVC(),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(),\n",
    "        'Neural Network': MLPClassifier(max_iter=1000)  # Using Multi-layer Perceptron for simplicity\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Loop over models, train, and evaluate each\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        print(f\"\\nEvaluating {model_name}...\")\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model\n",
    "        print(f\"\\nClassification Report for {model_name}:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(f\"Accuracy for {model_name}: {accuracy_score(y_test, y_pred)}\\n\")\n",
    "\n",
    "        \n",
    "        \n",
    "# Function to build a simple neural network model\n",
    "def build_nn_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Define features and target variable\n",
    "features = ['SmokerStatus_Current smoker - now smokes every day', ... ]  # List of feature column names\n",
    "target = 'HadHeartAttack'  # Target variable column name\n",
    "\n",
    "\n",
    "\n",
    "# Extract features and target variable\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Standardize the features (useful for SVM and Neural Network)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Train and evaluate regression models\n",
    "train_and_evaluate_models(X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "\n",
    "# Train and evaluate Neural Network\n",
    "model_nn = build_nn_model(X_train.shape[1])\n",
    "model_nn.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_data=(X_test_scaled, y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate Neural Network\n",
    "y_pred_nn = np.round(model_nn.predict(X_test_scaled)).flatten()\n",
    "print(\"\\nClassification Report for Neural Network:\")\n",
    "print(classification_report(y_test, y_pred_nn))\n",
    "print(f\"Accuracy for Neural Network: {accuracy_score(y_test, y_pred_nn)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3c354c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69969941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Read data from CSV file\n",
    "data = pd.read_csv(\"G_data.csv\")\n",
    "\n",
    "\n",
    "# Define features and target variable\n",
    "features = ['SmokerStatus_Current smoker - now smokes every day','SmokerStatus_Current smoker - now smokes some days','SmokerStatus_Former smoker','SmokerStatus_Never smoked'\n",
    ", 'AlcoholDrinkers', 'HadStroke', 'DifficultyWalking', 'Sex', 'AgeCategory_Age 18 to 24','AgeCategory_Age 25 to 29','AgeCategory_Age 30 to 34','AgeCategory_Age 35 to 39','AgeCategory_Age 40 to 44','AgeCategory_Age 45 to 49','AgeCategory_Age 50 to 54',\n",
    "'AgeCategory_Age 55 to 59','AgeCategory_Age 60 to 64','AgeCategory_Age 65 to 69'\n",
    ",'AgeCategory_Age 70 to 74', 'AgeCategory_Age 75 to 79','AgeCategory_Age 80 or older'  ,'RaceEthnicityCategory_Black only, Non-Hispanic','RaceEthnicityCategory_Hispanic','RaceEthnicityCategory_Multiracial, Non-Hispanic',\n",
    "'RaceEthnicityCategory_Other race only, Non-Hispanic','RaceEthnicityCategory_White only, Non-Hispanic', 'HadDiabetes_No','HadDiabetes_No, pre-diabetes or borderline diabetes','HadDiabetes_Yes','HadDiabetes_Yes, but only during pregnancy (female)'\n",
    ", 'PhysicalHealthDays', 'GeneralHealth_Excellent','GeneralHealth_Fair','GeneralHealth_Good','GeneralHealth_Poor','GeneralHealth_Very good'\n",
    ", 'HadAsthma', 'HadKidneyDisease', 'HadSkinCancer']\n",
    "target = 'HadHeartAttack'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create X and y arrays and convert to numpy array\n",
    "X = data[features].to_numpy()\n",
    "y = data[target].to_numpy() \n",
    "\n",
    "\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Create and train model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)  \n",
    "\n",
    "\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "\n",
    "# Generate and print classification report\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f790df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('G_data.csv')\n",
    "\n",
    "# Update the column names based on your dataset\n",
    "features = ['SmokerStatus_Current smoker - now smokes every day', 'SmokerStatus_Current smoker - now smokes some days',\n",
    "            'SmokerStatus_Former smoker', 'SmokerStatus_Never smoked', 'AlcoholDrinkers', 'HadStroke',\n",
    "            'DifficultyWalking', 'Sex', 'AgeCategory_Age 18 to 24', 'AgeCategory_Age 25 to 29',\n",
    "            'AgeCategory_Age 30 to 34', 'AgeCategory_Age 35 to 39', 'AgeCategory_Age 40 to 44',\n",
    "            'AgeCategory_Age 45 to 49', 'AgeCategory_Age 50 to 54', 'AgeCategory_Age 55 to 59',\n",
    "            'AgeCategory_Age 60 to 64', 'AgeCategory_Age 65 to 69', 'AgeCategory_Age 70 to 74',\n",
    "            'AgeCategory_Age 75 to 79', 'AgeCategory_Age 80 or older', 'RaceEthnicityCategory_Black only, Non-Hispanic',\n",
    "            'RaceEthnicityCategory_Hispanic', 'RaceEthnicityCategory_Multiracial, Non-Hispanic',\n",
    "            'RaceEthnicityCategory_Other race only, Non-Hispanic', 'RaceEthnicityCategory_White only, Non-Hispanic',\n",
    "            'HadDiabetes_No', 'HadDiabetes_No, pre-diabetes or borderline diabetes', 'HadDiabetes_Yes',\n",
    "            'HadDiabetes_Yes, but only during pregnancy (female)', 'PhysicalHealthDays', 'GeneralHealth_Excellent',\n",
    "            'GeneralHealth_Fair', 'GeneralHealth_Good', 'GeneralHealth_Poor', 'GeneralHealth_Very good', 'HadAsthma',\n",
    "            'HadKidneyDisease', 'HadSkinCancer']\n",
    "\n",
    "target = 'HadHeartAttack'\n",
    "\n",
    "df[features] = df[features].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X, y = sm.fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(n_estimators= 500 , max_depth= 3 , learning_rate = 0.1)\n",
    "\n",
    "xgb.fit(X_train , y_train);\n",
    "\n",
    "\n",
    "print (xgb.score(X_train , y_train))\n",
    "print (xgb.score(X_test , y_test))\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print(classification_report(y_test,xgb.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
